# Gradient Boosted Neural Network-Multi-Output

Gradient Boosted Neural Network-Multi-Output or GBNN-MO model is a novel training procedure for shallow and deep neural networks. The GBNN-MO is specifically developed for single and multi-output regression problems. The GBNN-MO is developed over the [GBNN](https://github.com/GAA-UAM/GBNN) model.


# About
The focus of this package is to provide related examples of the paper's experiments and results. You can reproduce our paper's results with the help of this package.

The described and developed method is based on the GBNN paper.
The main algorithm and codes are stored [here](https://github.com/GAA-UAM/GBNN).

# install
To run the examples of this package, you have to install the GBNN package from [here](https://github.com/GAA-UAM/GBNN).

```bash
pip install gbnn
```

# Citation
To cite the [paper](https://www.esann.org/sites/default/files/proceedings/2022/ES2022-95.pdf), use the following BibTex format

```txt
@inproceedings{DBLP:conf/esann/EmamiM22,
  author       = {Seyedsaman Emami and
                  Gonzalo Mart{\'{\i}}nez{-}Mu{\~{n}}oz},
  title        = {Multioutput Regression Neural Network Training via Gradient Boosting},
  booktitle    = {30th European Symposium on Artificial Neural Networks, Computational
                  Intelligence and Machine Learning, {ESANN} 2022, Bruges, Belgium,
                  October 5-7, 2022},
  year         = {2022},
  url          = {https://doi.org/10.14428/esann/2022.ES2022-95},
  doi          = {10.14428/esann/2022.ES2022-95}
}
```


## Key members of Gradient Boosted Neural Network - Multi Output

* [Gonzalo Martínez-Muñoz](https://github.com/gmarmu)
* [Seyedsaman Emami](https://github.com/samanemami)

# GBNN Version 
0.0.2

## Updated
01 Jul 2022

# Date-released
01 Jan 2022
